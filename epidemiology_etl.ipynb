{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epidemiology - ETL Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is organized in the following sections:\n",
    "* [Step 0 - Preliminary: Viewing the data](#0)\n",
    "* [Step 1 - Checking for duplicates](#1)\n",
    "* [Step 2 - Checking for missing values](#2)\n",
    "* [Step 3 - Imputing/dropping missing values](#3)\n",
    "* [Step 4 - Ensuring Correct Datatypes](#4)\n",
    "* [Step 5 - Preparation for merging](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "## Step 0 - Preliminary: Viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology = pd.read_csv('data/epidemiology.zip') #KEEP FOR SCRIPT -- EPIDEMIOLOGY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the data\n",
    "epidemiology.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The epidemiology dataset has 3161033 rows and 10 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## Step 1 - Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicates\n",
    "epidemiology.duplicated().any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates in the whole dataset, so we can continue to check the datatype of each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## Step 2 - Checking for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows the number of missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows the proportion of missing values with respect to the total number of values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology.isna().sum() / len(epidemiology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values, so we will proceed to either drop or impute them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## Step 3 - Imputing/dropping missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the new_tested and cumulative_tested columns as both these are nearly completely null.\n",
    "Also, there is no way to calculate/impute tested as we would need another column with the confirmed negative cases of covid (which we don't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology = epidemiology.drop(columns = ['new_tested', 'cumulative_tested']) #KEEP FOR SCRIPT -- EPIDEMIOLOGY 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As recovered columns are over 90% null, we also drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology = epidemiology.drop(columns = ['new_recovered', 'cumulative_recovered']) #KEEP FOR SCRIPT -- EPIDEMIOLOGY 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace nulls in 'new_confirmed' by calculating its value from consecutive 'cumulative_confirmed' values\n",
    "for i in range(len(epidemiology)):\n",
    "    if pd.isna(epidemiology.at[i, \"new_confirmed\"]) and epidemiology.at[i, \"location_key\"] == epidemiology.at[i - 1, \"location_key\"]:\n",
    "        epidemiology.at[i, \"new_confirmed\"] = epidemiology.at[i, \"cumulative_confirmed\"] - epidemiology.at[i - 1, \"cumulative_confirmed\"]\n",
    "# Step 2: Handle rows with minimum dates\n",
    "min_date_indices = epidemiology.groupby('location_key')['date'].idxmin()\n",
    "min_date_rows = epidemiology.loc[min_date_indices].copy()\n",
    "min_date_rows.loc[min_date_rows['new_confirmed'].isnull(), 'new_confirmed'] = min_date_rows['cumulative_confirmed']\n",
    "epidemiology.update(min_date_rows)\n",
    "\n",
    "# Step 3: Sort by 'location_key' and 'date'\n",
    "epidemiology = epidemiology.sort_values(by=['location_key', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Step 4: Forward-fill 'cumulative_deceased', leaving all-null groups as NaN\n",
    "epidemiology['cumulative_deceased'] = epidemiology.groupby('location_key')['cumulative_deceased'].transform(\n",
    "    lambda group: group.ffill() if group.notna().any() else group\n",
    ")\n",
    "\n",
    "# Step 5: Calculate 'new_deceased', leaving all-null groups as NaN\n",
    "epidemiology['new_deceased'] = epidemiology.groupby('location_key')['cumulative_deceased'].transform(\n",
    "    lambda group: group.diff() if group.notna().any() else group\n",
    ")\n",
    "\n",
    "# Step 6: Clip negative values\n",
    "epidemiology['new_deceased'] = epidemiology['new_deceased'].clip(lower=0)\n",
    "epidemiology['new_confirmed'] = epidemiology['new_confirmed'].clip(lower=0)\n",
    "\n",
    "# Step 7: Extract region code\n",
    "epidemiology['region'] = epidemiology['location_key'].str[3:5]\n",
    "\n",
    "# Step 8: Calculate 'x' (average of new_deceased / new_confirmed) per region and date\n",
    "region_date_avg = epidemiology.groupby(['region', 'date']).apply(\n",
    "    lambda group: group['new_deceased'].sum() / group['new_confirmed'].sum()\n",
    "    if group['new_confirmed'].sum() > 0 else 0\n",
    ").rename('x').reset_index()\n",
    "\n",
    "# Step 9: Merge 'x' into the original DataFrame\n",
    "epidemiology = epidemiology.merge(region_date_avg, on=['region', 'date'], how='left')\n",
    "\n",
    "# Step 10: Impute missing 'new_deceased' values using 'x * new_confirmed'\n",
    "epidemiology['new_deceased'] = epidemiology.apply(\n",
    "    lambda row: (\n",
    "        math.ceil(row['x'] * row['new_confirmed']) \n",
    "        if (row['x'] * row['new_confirmed']) % 1 > 0.05 \n",
    "        else round(row['x'] * row['new_confirmed'])\n",
    "    ) if pd.isna(row['new_deceased']) else row['new_deceased'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step 11: Drop temporary columns\n",
    "epidemiology.drop(columns=['region', 'x'], inplace=True)\n",
    "\n",
    "# Step 12: Recalculate 'cumulative_deceased'\n",
    "epidemiology['cumulative_deceased'] = epidemiology.groupby('location_key')['new_deceased'].transform(lambda group: group.cumsum())\n",
    "\n",
    "# Final sorting\n",
    "epidemiology = epidemiology.sort_values(by=['location_key', 'date']).reset_index(drop=True)\n",
    "epidemiology['date'] = pd.to_datetime(epidemiology['date'], format=\"%Y-%m-%d\")\n",
    "epidemiology['date'] =  epidemiology['date'].dt.to_period(\"W\") \n",
    "epidemiology= epidemiology.groupby(['date','location_key'])[['new_confirmed', 'new_deceased', 'cumulative_confirmed', 'cumulative_deceased']].sum()\n",
    "epidemiology = epidemiology.reset_index() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some checks to be sure that these columns have been dropped correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check 1\n",
    "epidemiology.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check 2\n",
    "epidemiology.isna().sum() / len(epidemiology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check 3\n",
    "epidemiology.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## Step 4 - Ensuring correct datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring the datatypes we have are correct\n",
    "epidemiology.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatype of date is incorrect, it should be of type datetime64[ns] and not object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we changed the datatype of the column 'date':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology['date'] = pd.to_datetime(epidemiology['date'], format=\"%Y-%m-%d\") #KEEP FOR SCRIPT -- EPIDEMIOLOGY 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the datatypes of each of the columns again to be 100% sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the columns appear to have the appropriate datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One final check\n",
    "\n",
    "epidemiology.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Preparation for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the column date from day to week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology['date'] =  epidemiology['date'].dt.to_period(\"W\") #KEEP FOR SCRIPT -- EPIDEMIOLOGY 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by date (week) and location_key, as these are the indices we want.\n",
    "\n",
    "We use the sum metric for the group by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology= epidemiology.groupby(['date','location_key'])[['new_confirmed', 'new_deceased', 'cumulative_confirmed', 'cumulative_deceased']].sum()\n",
    "#KEEP FOR SCRIPT -- EPIDEMIOLOGY 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "epidemiology = epidemiology.reset_index() #KEEP FOR SCRIPT -- EPIDEMIOLOGY 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
